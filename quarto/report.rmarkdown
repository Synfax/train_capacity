---
title: "Train Station Upzoning Rankings"
author: "Paul Spasojevic"
date: "10/17/24"
params: 
  station: "Brunswick"
css:
 - index.css
 - nav_fixes.css
format: 
  html: 
    grid: 
      body-width: 900px
    page-layout: article  
    theme: zephr
    code-fold: false
    toc: true
    toc-location: left
    toc-expand: true
    toc-depth: 3
    
---

```{r warning=FALSE,message=FALSE}
#| echo: false 

station = params$station

library(tidyverse)
library(sf)
library(leaflet)
library(stringr)
library(RColorBrewer)
library(plotly)
library(ggridges)
library(reactablefmtr)

source('../r/station_functions.R')
source('../r/constants.R')
source('../r/transform.R')
source('../r/graphs.R')
source('../r/theme.R')

n_slice = 25
```



Melbourne is going to have to make some choices soon about where to build more housing.

Train stations are ideal locations to upzone, they connect the city together and generally have some surrounding infrastructure. 

However, policymakers face trade offs in choosing which stations to upzone. For example, stations close to the city may be best in terms of commute distance may already be developed or the trains may be very busy. Stations further away may have better existing land use, but no nearby amenities or poor service frequency.

The purpose of this report is to tackle these trade-offs by building a robust and data-driven framework to identify the train stations that are best suited for this broad upzoning.

The chosen metrics are:

-   Zoning suitability
<!-- -   Potential number of new homes -->
-   Train service frequency in peak
-   Available capacity on train line.
-   Number of local services within a 500m walk
-   Proximity to the CBD
-   Existing transport infrastructure.

These are further explained in the Methodology section below.

Ths contents of this page may be different to other reports in this style. Users are able to download the code behind this report and adjust the importance of each of the factors in the model to their liking, and regenerate the report. 

Therefore, the rankings (and content of this report) are highly sensitive to change, and the report can be read with any rankings and any weightings. In this way, it is a best described as a tool, rather than a definitive source of truth.

::: margin-aside 
The rankings are highly sensitive to the weights chosen to combine individual metrics. See 'Transformation'.
:::


This piece is driven largely by Train Patronage data, released by DataVic, which generates important service frequency and patronage information for each station. OpenStreetMap is used for finding nearby amenities, and VicPlan for analysing zoning suitability. Other transport information is pulled from GTFS Static. 


# Methodology

This sections aims to describe the process used to rank each train station in Melbourne for upzoning. In doing so, the page steps through each of the metrics used to quantify different aspects of the station, before concluding with an explanation of the process used to turn the raw data into a score for easy comparison.


Metrics were chosen based on two factors

-   data being available to support the analysis
-   data is able to be measured by a single number

The rankings are intended to capture which stations should be upzoned as a priority **right now** without having to amend any legislation, alter zoning, change public transport service frequencies or build new infrastructure. Hence, some metrics are a representation of the day they were calculated and are likely to change over time, requiring the model to be re-run when new data is available.


This section describes the functions that generate the station rankings, of which the code is primarily here on [GitHub](https://github.com/Synfax/train_capacity/blob/main/r/station_functions.R).

### Service Frequency

The metric is calculated by using PTV's [Patronage Data](https://discover.data.vic.gov.au/dataset/train-service-passenger-counts), which details the patronage for each train service in Melbourne. For a given station, the average number of departures is taken across two periods and directions:

\- Between 7 and 10am towards Flinders Street

\- Between 4 and 7pm away from Flinders Street

The average of these two periods then comprises the final score. It is measured in 'Services per hour'. For example 4 services per hour corresponds to a service every 15 minutes.

Public holidays, school holidays and weekends are excluded from the data.

A limitation of only capturing peak services is that it is a poorer indicator for those who do not subscribe to the typical 9-5 office commute. On the other hand, peak hours are when most people use trains, and an average over the whole day may drown out information regarding service frequency when people use them most.

### Number of Local Services

While train stations themselves are useful for travelling around the city, ideal upzoning locations also have many local amenities and are in a nice neighbourhood.

To measure this, critical amenities are pulled from `OpenStreetMap` using the `osmdata` package. These are: `r critical_variables$val`.

::: column-margin
The choice of the amenities is arbitrary, and intended to measure essential living necessities that makes neighbourhoods nice. A further benefit is that for the chosen amenities, OpenStreetMap contains reasonably accurate data. More extravagant and precise amenity choices could be limited by poor data.
:::

This yields the number of each type of amenity for any given station.

However, for the overall transformation process to work, these amenity numbers must be compressed into a single number for comparison with other stations.

One could sum all the amenities to get a total number of services nearby, however, this results in no difference between a station surrounded by 100 cafes, or one with 20 of each amenity. Other methods, such as median number of amenities or mean number suffer from similar problems.

To combine these amenity counts into a single value, an xmin-xmax transformation is used, which is the same process for how each station is assigned its rank which is described at the end of this document.

Each column is transformed through:

$$
x = \frac{x - \min{x} }{ \max{x} - \min{x} }
$$

In this way, each value is now represented as a percentage of the range (max - min) of ALL stations in the sample, bounded between zero and one. A zero corresponds to the lowest value out of all stations, and a one corresponds to the highest value.

After the transformation is applied, each station has a 0-1 value for each amenity type, which can be summed together to form a single metric for how many local services are nearby.

::: column-margin
No weighting is applied for this sum. Each amenity type is treated equally as important as each other. It would be trivial to change the amenity weights in the code and re-run if desired.
:::

The scoring method takes into account that raw numbers mean different things for different amenities, which a simple summation or mean would not consider. For example, having 45 cafes in an area is less important than having 45 schools, although without additional manual weighting, a mean or sum would be unable to distinguish the two.

The downside is that the resulting 'value' does not have a nice interpretation.

### Distance to CBD

Stations closer to the CBD are likely to have higher land prices, which makes upzoning far more economically feasible. They are also likely to have increased job access.

Therefore, distance is included 'as the crow flies' from the station to Flinders Street Station, in metres.

### Existing Transport Infrastructure

While rail provides high-capacity service in and out of the CBD, it is only in a radial direction. It is also important to measure the other transport modes that service the properties near the stations, trams and buses.

The model works by first finding which [bus stops](https://discover.data.vic.gov.au/dataset/ptv-metro-bus-stops) and [tram stops](https://discover.data.vic.gov.au/dataset/ptv-metro-tram-stops) are within the specified radius of the train station, and pulling the list of services which service those stops.

The next step of the model uses the [PTV GTFS Timetable API](https://discover.data.vic.gov.au/dataset/timetable-and-geographic-information-gtfs) to pull service timetables on a typical weekday. For each route, the average number of departures per hour is calculated ([Code](https://github.com/Synfax/train_capacity/blob/main/r/tram_gtfs_analysis.R)).

A weight is applied to the tram routes, as typically they can carry at least twice the number of passengers a bus can. As such, they are weighted twice that of buses.

An important consideration is that this measure does not factor in the number of stops within the radius of the station, only that there is at least one stop.

The stop counts were not included as having more stops does not neccessarily mean the area is better connected: they could be served infrequently, be clustered on the edge of the radius, or be so close together the service is slow.

A downside of this method is it does not (and could not reasonably) consider the direction the services travel, or if the services travel to useful places.

### Zoning suitability

This measure intends to capture the suitability of existing zoning surrounding train stations.

An ideal station would have many low density residential lots that are able to be redeveloped and not subject to external heritage controls.

Therefore, a 'suitable lot' is defined as:

-   Either Neighbourhood Residential or General Residential

-   Not under any heritage control

The measure is calculated as the area of suitable properties in square metres, divided by the total area of all properties within a suitable radius. Train stations that score poorly in this metric are likely to either be mostly non-residential already, or be subject to extreme heritage controls, which meets the intention for this metric.

[Data](https://discover.data.vic.gov.au/dataset/vicmap-planning-planning-scheme-overlay-polygon1) from DataVic.

<!-- ### Zoned Capacity -->

<!-- Zoned capacity is a measure of how many dwellings could fit in an area, given the current zoning. It is a theoretic maximum. This section looks at the current zoned capacity, and compares it to a theoretic zoned capacity under 'Missing Middle' zoning. To reiterate, the potential future zoned capacity is **a theoretic maximum**, and extremely unlikely to be realised if upzoning occured. -->

<!-- The numbers as theoretical limits are from YIMBYMelbourne's *Housing Targets* report, with initial yields from Michael Buxton, tweaked by Jonathan Nolan. [Code for the brave](https://github.com/Synfax/train_capacity/blob/main/r/add_mm_zoning_info.R) -->

### Line Capacity


```{r warning=FALSE,message=FALSE}
#| echo: false 

station = 'Victoria Park'

station_lines = readRDS('../r_objects/stations_with_lines.Rdata') %>%
  filter(Station_Name == station) %>%
  pull(lines) %>%
  unlist() %>%
  as.vector()

station_targets = readRDS('../r_objects/target_stations.Rdata') %>% 
  filter(Station_Name == station) %>%
  pull(targets) %>%
  unlist() %>%
  as.vector() %>%
  first()

```


This metric aims to measure the amount of space available on trains passing through this station, as there is little point upzoning if there is no capacity to move people. It uses the DataVic [Patronage Data](https://discover.data.vic.gov.au/dataset/train-service-passenger-counts).

However, for stations in the middle of a train line, passengers will typically continue to board the train until the city. This means that it is not useful to only look at the patronage as trains pass through a given station as more passengers may board later.

Instead, it is best to look at the average number of passengers on trains at their last station before the CBD as this is when trains are their busiest. This gives a better measure of how busy the line itself is overall.

Let's use Victoria Park as an example.

##### Sample Process for `r station`

1.  Find the train line(s) that serve `r station`: `r station_lines`

2.  For each train line, find the station nearest to the CBD. These are by definition the same for each line: `r station_targets`.

3.  For each of these stations just before the CBD, calculate the average patronage of train services at that station, but restrict the search to only train services on the lines identified in step 1.

The process described above yields a single score for all stations that share the same lines. These values are shown below to try and describe the process.

::: {.graph .column-body}


```{r warning=FALSE,message=FALSE}
#| echo: false 



station_lines = readRDS('../r_objects/stations_with_lines.Rdata') 

station_rankings = readRDS('../r_objects/station_rankings.Rdata') %>%
  rename(Station_Name = "station") %>%
  as.data.frame()

(station_rankings %>%
  filter_stations(., "Station_Name") %>%
  left_join(station_lines, by = 'Station_Name') %>%
  select(average_peak_service_cap, lines) %>%
  unique() %>%
  rowwise() %>%
  mutate(lines = lines %>% unlist() %>% as.vector() %>% paste0(.,collapse = ',') ) %>%
  ggplot(mapping = aes(y = reorder(lines, average_peak_service_cap), x = average_peak_service_cap, fill = average_peak_service_cap)) +
  scale_fill_gradientn(colors = create_green_palette(11)) +
  geom_col() +
  theme_report() +
  theme(legend.position = 'none') +
  xlab("Mean number of people on peak train before flinders") +
  ylab("Lines serving station")) %>%
  ggplotly()

```


:::

\

Stations only served by the Sunbury line typically have the most packed trains, whereas Frankston only stations are typically the emptiest.

## Final values

The table below contains the raw values that have been calculated for each station. The table is also searchable.

::: {.table .column-page}

```{r warning=FALSE,message=FALSE}
#| echo: false 


station_rankings = readRDS('../r_objects/station_rankings.Rdata') %>%
  remove_null_weighted_cols() %>%
  rename(!!!remove_null_weighted_translations(translations_simple_inv)) %>%
  mutate(across(-station, as.numeric)) %>%
  mutate(across(where(is.numeric), .fns = function(x) {round(x,2)}))

station_rankings %>%
  reactable( pagination = T,
    defaultColDef = colDef(),
    columns = list(
      station = colDef(name = 'Station', filterable = T)
    ))

```

:::

## Transformation Process



Each raw score is in different units, so the first task is to transform all the metrics into something that can be summed into one total score.

This is achieved by scaling each column (of all the scores) so that each value is relative to the maximum and minimum values from other stations, also known as xmin-xmax scaling. The end result is a value between zero and 1 across all metrics, allowing an easy summation.

$$
x = \frac{x - \min{x} }{ \max{x} - \min{x} }
$$

::: callout-note
One downside of the xmin-xmax scaler is its high sensitivity to outliers. Very high or very low values imply that reasonable variance in the original data is flattened to very similar values after scaling.
:::

#### Sample Transformations

An example of a good transformation is shown below. Hover over the data points to see their values. 


```{r warning=FALSE,message=FALSE}
#| echo: false 

# dummy_data = data.frame(uniform = runif(10, 0, 15), poisson = rpois(10, 2), manual = c(rnorm(9, 10, 2), 30) )
# 
# saveRDS(dummy_data, '../r_objects/dummy_data.Rdata')

transformed_data <- readRDS('../r_objects/dummy_data.Rdata')  %>%
  mutate(across(everything(), 
                .fns = list(transf = ~(. - min(., na.rm = TRUE)) / 
                                     (max(., na.rm = TRUE) - min(., na.rm = TRUE))),
                .names = "{.col}_{.fn}"))


plot_transformation <- function(data, var_name, title) {
  # Prepare the data
  plot_data <- data %>%
    select({{ var_name }}, paste0({{ var_name }}, "_transf")) %>%
    mutate(id = row_number()) %>%
    pivot_longer(cols = -id, names_to = "type", values_to = "value") %>%
    mutate(type = if_else(type == {{ var_name }}, "Original", "Transformed"))

  # Create the plot
  (ggplot(plot_data, aes(x = reorder(id, value), y = value, color = type)) +
    geom_point() +
    geom_line(aes(group = id), color = "grey", alpha = 0.5) +
    scale_color_manual(values = c("Original" = "#283696", "Transformed" = "#ba1b21")) +
    labs(title = title,
         x = "Observation ID",
         y = "Value",
         color = "Data Type") +
    theme_report() +
    theme(legend.position = "top") ) %>%
    ggplotly()
}

# Example usage for a variable named 'example_var'
plot_transformation(transformed_data, 'uniform', '') 


```

\

The graph above shows a 'good' transformation. There are no notable outliers in the original data, which means the denominator in the transformation is likely small. The key sign of a healthy transformed variable is that transformed values are spread nicely between zero and one, which is the case above. 

An example of a 'bad' transformation is also shown. Hover over the data points to see their values. 


```{r warning=FALSE,message=FALSE}
#| echo: false 

plot_transformation(transformed_data, 'manual', '') 


```


\

The graph above demonstrates the issue with xmin-xmax scaling. One large outlier (30 in original data) makes the denominator of the transformation very large. This means that most of the transformed values are very low. For example, the third largest number in the original sample (10.03) is only awarded a score of 0.07, despite being larger than 7 other values.

The result of this is the variance in the original data (from ~8 to ~12) is not reflected adequately in the transformation ranks. From the perspective of the ranking mechanism all stations in that range look the same, despite having large real differences.

#### Inverting some metrics

For some metrics however, a larger value implies a station that is less suited for upzoning. In this report these are:

- Distance to CBD: Higher values mean stations are futher away, and less suited for upzoning

- Patronage on train line: Higher values mean the train line(s) are more congested, meaning the station is less suited to upzoning.

<!-- To deal with this problem, weights are applied to each metric, with negative weights representing unwanted metrics. This also allows customisation of the model by any interested parties. -->

To deal with this issue, variables are inverted ($x = 1 - x$), such that higher values are now beneficial, rather than detrimental. 

#### Variable Weighting

With each variable bounded between zero and one, and inverted such that higher values are more beneficial for all variables, the ranking mechanism sums the values together to produce a 'final score' with a maximum of seven.

There is potential, however, for certain variables to be more important than others. For example, train frequency could be worth twice as much as 'Potential new homes'.

The model has weighting built in, although by default everything is set to one, which corresponds to a summation of scores. 

::: {.column-aside}
Weights can be changed by altering `r/constants.R`.
:::



```{r warning=FALSE,message=FALSE}
#| echo: false 

# weights_df <- weights %>%
#   as.data.frame() 
# 
# weights_df = weights_df %>%
#   mutate(var = rownames(weights_df))
#   
# colnames(weights_df) = c('weight' , 'variable')
# 
# weights_df = weights_df %>%
#   pivot_wider(names_from = variable, values_from = weight)
# 
# rownames(weights_df) = "Weight"
# 
# weights_df %>%
#   rename(!!!translations_simple_inv) %>%
#   reactable(rownames = T, theme = sandstone())

```



These transformed scores are then summed to produce a final score. The largest possible score is the sum of the weights, with a default of one each meaning a maximum score of `r sum(weights)`.

::: callout-note

There are some restrictions placed on final rankings:

-   City loop stations are excluded as they can't be upzoned further.

-   Edge transfer stations (North Melbourne, South Yarra, Richmond) were excluded due to extreme outliers in the data impacting the transformation process.

-   Stations further than 25km of Flinders Street are excluded as they are generally economically unfeasible to upzone.

:::

<!-- ## Example Transformation -->


```{r warning=FALSE,message=FALSE}
#| echo: false 

# example_rankings = readRDS('../r_objects/station_rankings.Rdata') %>%
#   filter(station %in% c('Brunswick', 'Merri', 'Carnegie')) %>%
#   mutate(across(-station, as.numeric)) %>%
#   mutate(across(where(is.numeric), .fns = function(x) {round(x,2)}))

#example_rankings %>% reactable()

#example_transformed = transform_scores_xminxmax(example_rankings)

#example_transformed %>% reactable()


```


## Transformed Scores

The table below shows the full list of (valid) stations and their transformed values. A *rough* interpretation of transformed values is below.

| Transformed Value | Interpretation |
|-------------------|----------------|
| 0-0.35            | Poor           |
| 0.35 - 0.6        | Low            |
| 0.6 - 0.8         | Good           |
| 0.8 - 1           | Excellent      |

The table is both searchable and able to be ordered. Users can type a station of their desire into the search bar, or click on the table headers to see the 'best' and 'worst' station for each metric.

::: {.table .column-page}

```{r warning=FALSE,message=FALSE}
#| echo: false 

transformed_scores = readRDS('../r_objects/transformed_scores.Rdata') %>%
  remove_null_weighted_cols() %>%
  mutate(across(-station, as.numeric)) %>%
  mutate(across(where(is.numeric), .fns = function(x) {round(x,2)}))

transformed_scores %>%
  rename(!!!remove_null_weighted_translations(translations_simple_inv)) %>%
  reactable( 
             defaultSorted = 'score',
             defaultSortOrder = 'desc',
             defaultColDef = colDef(),
             columns = list(
                station = colDef(name = 'Station', filterable = T)
             ) )

```

:::

# Results

The chart below shows the 10 stations with the highest rankings. 

::: {.graph .column-body}


```{r warning=FALSE,message=FALSE}
#| echo: false 

top_10_chart()

```

:::


### Top Scores by Line

The below plot shows which train lines how the `r n_slice` top stations are located on. For stations on many lines, each line is counted once.

::: {.column-aside}
This is why the number of lines sums to more than `r n_slice`
:::

::: {.graph .column-body}

```{r warning=FALSE,message=FALSE}
#| echo: false 



station_lines = readRDS('../r_objects/stations_with_lines.Rdata') 

transformed_scores = readRDS('../r_objects/transformed_scores.Rdata') %>%
  as.data.frame() %>%
  rename(Station_Name = "station") %>%
  arrange(desc(score)) %>%
  mutate(rank = row_number())

score_by_line <- (transformed_scores %>%
  left_join(station_lines, by = 'Station_Name') %>%
  slice_head(n = n_slice) %>%
  select(Station_Name, rank, lines) %>%
  unnest(lines) %>%
  count(lines, sort = T) %>%
  filter(lines != "Richmond and City Loop") %>%
  rename(line = 'lines') %>%
  left_join(line_groups, by = 'line') %>%
  ggplot(., mapping = aes(x = reorder(line, -n) , y = n)) +
  theme_report() +
  theme(legend.position = 'top') +
  geom_col(aes(fill = group)) +
  scale_fill_manual(values = setNames(colours$colour, colours$group)) +
  guides(x = guide_axis(angle = 45)) +
  xlab("Train Line") +
  ylab(paste0("Number of stops in top ", n_slice )) ) %>%
  ggplotly() %>%
  layout(xaxis = list(tickangle = -45)) %>%
  layout(legend = list(
    orientation = "h",    # horizontal orientation
    y = 1.1,             # position above plot
    x = 0.5,             # centered
    xanchor = "center"   # anchor point for centering
  ))


score_by_line

```

:::



### By LGA

The best stations for upzoning are not equally distributed across Melbourne.

Hover over the bar chart below for an interactive effect.

::: {.graph .column-body}


```{r warning=FALSE,message=FALSE}
#| echo: false 



top_stations_by_lga(n_slice = n_slice) 

```

:::

### Adjusted for station density

In viewing the graph above, it is possible that any LGA with a high number of stations in the top `r n_slice` is just a reflection that the LGA has many stations compared to others.

The chart below corrects for this by instead calculating the ratio of stations that are ranked in the top `r n_slice` to the total number of stations in the LGA. For example, a ratio value of 20 for Merri-Bek can be interpreted as 20% of all train stations in Merri-Bek are included in the top `r n_slice`.


```{r warning=FALSE,message=FALSE}
#| echo: false 

prefix = '../'
  
  transformed_scores = readRDS(paste0(prefix, 'r_objects/transformed_scores.Rdata')) %>%
    as.data.frame() %>%
    rename(Station_Name = "station")
  
  locations = readRDS(paste0(prefix, 'r_objects/locations.Rdata')) 
  
  scores_for_lga = transformed_scores %>%
    left_join(locations, by = 'Station_Name') %>%
    st_as_sf(coords = c('lng','lat')) %>%
    arrange(desc(score)) %>%
    mutate(rank = row_number())
  
  scores_for_lga = slice_head(scores_for_lga, n = n_slice) %>%
    select(Station_Name) 
  
  scores_for_lga = st_set_crs(scores_for_lga, 'wgs84') %>%
    st_transform(crs = 7844)
  
  #load geometries 
  
  lga <- read_sf(paste0(prefix, 'shapefiles/lga_boundaries/LGA_2023_AUST_GDA2020.shp')) 
  
  lga_with_n_sf <- st_join(lga, scores_for_lga) %>%
    filter(!is.na(Station_Name)) %>% 
    group_by(LGA_NAME23) %>%
    summarise(n = n())
  
  locations = st_as_sf(locations, coords = c('lng','lat'), crs = st_crs(lga), agr = 'constant')
  
  
  number_of_stations_in_lga <- st_join(lga, locations) %>%
    filter(!is.na(Station_Name)) %>% 
    group_by(LGA_NAME23) %>%
    summarise(total_stations = n())
  
  (lga_with_n_sf %>%
    st_drop_geometry() %>%
    left_join(number_of_stations_in_lga %>%
                st_drop_geometry(), by = 'LGA_NAME23') %>%
    mutate(ratio = (n / total_stations)*100 ) %>%
     ggplot(mapping = aes(x = ratio, y = reorder(LGA_NAME23, ratio), fill = ratio ) ) +
       geom_col()  +
      theme_report() +
      theme(legend.position = 'none') +
      theme(axis.title.y = element_blank()) +
      scale_fill_gradientn(colors = create_green_palette(11)) +
    xlab("Station Ratio (%)")) %>%
    ggplotly()
   
```


A downside of this approach is that high ratios don't necessarily infer the LGA is suited for upzoning. 

For example, an LGA with 1 out of a total of 2 train stations in the rankings generates the same ratio as an LGA with 10 out of 20. However, the LGA with 10 out of 20 is far more 'suitable'.

# Additional Analysis



### Distributions of Scores


Shown below are density plots of the scores, both raw and after transformation. The density plots seek to show how the underlying data is distributed, as well as how many extreme values there are.



#### Transformed scores

::: {.graph .column-body}


```{r warning=FALSE,message=FALSE}
#| echo: false 
#| fig-width: 8
#| fig-height: 7

# translations = c(
#   'grz_nrz_pc' = 'Zoning suitability',
#   'capacity_delta' = 'Potential new homes',
#   'average_peak_service_freq' = 'Train frequency',
#   'average_peak_service_cap' = 'Available train capacity',
#   'walkability_score' = 'Local services',
#   'distance' = 'Distance to CBD',
#   'n_bus_tram' = 'Other transport infrastructure'
# )

transformed_scores = readRDS('../r_objects/transformed_scores.Rdata') %>%
  as.data.frame()

transformed_scores = transformed_scores %>%
  remove_null_weighted_cols() %>%
  select(-score) %>%
  pivot_longer(cols = -c('station')) %>%
  mutate(name = remove_null_weighted_translations(translations_simple, inv = F)[name])

  # mutate(name = str_wrap(name, width = 5))

# <- ggplot(transformed_scores) + geom_density(aes( x = value)) + facet_grid(rows = vars(name), scales = 'free') + theme_bw()

ggplot(transformed_scores, aes(x = value, y  = name, fill = name)) +
  geom_density_ridges(alpha = 0.5, bins = 30, stat = 'binline') +
  theme_ridges()  + 
  theme_report() +
  theme(legend.position = "none") + xlab("Transformed Score") +
  ylab("")


# ggplot(transformed_scores, aes(x = value, y  = name, fill = name)) +
#   geom_density_ridges(alpha = 0.5, bins = 30) +
#   theme_ridges()  + 
#   theme(legend.position = "none")




```

:::


::: column-margin
Created with `ggridgeline`.
:::

Transformed variables that are approximately uniformly distributed are the best suited for xmin-xmax transformations. Variables that display large spikes or have large gaps in data (such as Train Frequency) have worse interpretations after transformation.

Given that many variables are roughly flat and tend not to have large data gaps, xmin-xmax remains a suitable transformation for this project. 

#### Raw scores
::: {.graph .column-body}

```{r warning=FALSE,message=FALSE}
#| echo: false 
#| fig-width: 8

n_slice = 25

raw_scores = readRDS('../r_objects/station_rankings.Rdata') %>%
  filter_stations() %>%
  remove_null_weighted_cols()

  raw_scores = raw_scores %>%
  pivot_longer(cols = -c('station')) %>%
  mutate(name = remove_null_weighted_translations(translations_simple, inv = F)[name])


 ( ggplot(raw_scores) + geom_density(aes( x = value)) +
  facet_wrap(~ name, scales = 'free') +
  theme_bw() +
  theme_report() +
  theme(axis.text.y = element_blank()) + xlab("Raw score") + ylab("Density") ) 

```

:::

:::{.callout-note}
The same exclusion restrictions outlined in "Transformation Process" are applied here.
:::

Variables fall into two main categories:

- Rough pyramid shape with a skew (Zoning Suitability, Proximity to CBD, Potential new homes)

- Peak and then sudden decline (Local amenities, other transport connections)

Train frequency has fewer unique values and a high peak at approximately 6 services per hour, giving it a unique shape compared to other variables.


```{r warning=FALSE,message=FALSE}
#| echo: false 

# 
# station_lines = readRDS('../r_objects/stations_with_lines.Rdata') 
# 
# station_rankings = readRDS('../r_objects/station_rankings.Rdata') %>%
#   rename(Station_Name = "station") %>%
#   as.data.frame()
# 
# 
# (station_rankings %>%
#   filter_stations(., "Station_Name") %>%
#   left_join(station_lines, by = 'Station_Name') %>%
#   select(average_peak_service_cap, lines) %>%
#   unique() %>%
#   rowwise() %>%
#   mutate(lines = lines %>% unlist() %>% as.vector() %>% paste0(.,collapse = ',') ) %>%
#   ggplot(mapping = aes(y = reorder(lines, average_peak_service_cap), x = average_peak_service_cap)) +
#   geom_col() +
#   theme_minimal() +
#   xlab("Avg number of people on peak train before flinders") +
#   ylab("Lines serving station")) %>%
#   ggplotly()

```



### Best and Worst Stations

The table below displays the stations that are the best and the worst for each metric used in the ranking process.


```{r warning=FALSE,message=FALSE}
#| echo: false 

station_rankings = readRDS('../r_objects/station_rankings.Rdata')

station_rankings %>%
  filter_stations(name_var = 'station') %>%
  remove_null_weighted_cols() %>%
  select(station, where(is.numeric)) %>%
  pivot_longer(cols = -station, names_to = "column", values_to = "value") %>%
  group_by(column) %>%
  summarise(
    Highest_Value = station[which.max(value)],
    Lowest_Value = station[which.min(value)]
  ) %>%
  select(Column = column, everything()) %>%
  rowwise() %>%
  mutate(Column = translations_simple[Column]) %>%
  reactable(
    columns = list(
      Column = colDef(name = "Metric"),
      Highest_Value = colDef(name = "Highest Value"),
      Lowest_Value = colDef(name = "Lowest Value")
    )
  )

```



### Additional Information on Amenities

Since the 'Local Amenities' measure is a composite measure itself, it is also possible to look at the best and worst stations for each amenity type.


```{r warning=FALSE,message=FALSE}
#| echo: false 

station_walkability = readRDS('../r_objects/station_walkability.Rdata')
transformed_scores = readRDS('../r_objects/transformed_scores.Rdata')

station_walkability %>%
  filter(station %in% (transformed_scores %>% pull(station))) %>%
  select(station, where(is.numeric)) %>%
  pivot_longer(cols = -station, names_to = "column", values_to = "value") %>%
  group_by(column) %>%
  summarise(
    Highest_Value = paste0(station[which.max(value)], ": ", max(value)),
    Lowest_Value = paste0(station[which.min(value)], ": ", min(value))
  ) %>%
  select(Column = column, everything()) %>%
  reactable(
    columns = list(
      Column = colDef(name = "Amenity"),
      Highest_Value = colDef(name = "Highest Value"),
      Lowest_Value = colDef(name = "Lowest Value")
    )
  )

```


\

Collingwood leads the pack and is top of the class in bars, cafes, restaurants and supermarkets. 

For lowest values, there is more variance, with only Glen Iris being the lowest for two amenity types: bars and supermarkets.
